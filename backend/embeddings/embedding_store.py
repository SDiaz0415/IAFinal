import faiss
import numpy as np
import json
import os
import pickle
from sentence_transformers import SentenceTransformer
from collections import defaultdict, Counter
import re
from pathlib import Path

class EmbeddingStore:
    def __init__(self):

        # Construir la ruta relativa
        data_path = str(Path(__file__).resolve().parent.parent / "data" / "data.json")
        index_path = str(Path(__file__).resolve().parent.parent / "data" / "faiss_index.bin")
        docs_path = str(Path(__file__).resolve().parent.parent / "data" / "docs.pkl")

        """Inicializa el almac√©n de embeddings con la ruta al JSON"""
        self.model = SentenceTransformer("all-mpnet-base-v2")
        self.index = None
        self.docs = []
        self.technical_terms = set()
        self.json_path = data_path #json_path
        self.INDEX_FILE = index_path #"backend/data/faiss_index.bin"
        self.DOCS_FILE = docs_path #"backend/data/docs.pkl"
        self.load_or_create_index()

    def load_or_create_index(self):
        """Carga o crea el √≠ndice FAISS"""
        if os.path.exists(self.INDEX_FILE) and os.path.exists(self.DOCS_FILE):
            self.load_index()
        else:
            self.create_index()
            if os.path.exists(self.json_path):
                self.load_json_data()

    def create_index(self):
        """Crea un nuevo √≠ndice FAISS"""
        d = 768  # Dimensi√≥n del embedding
        self.index = faiss.IndexFlatL2(d)
        print("√çndice FAISS creado exitosamente")

    def load_index(self):
        """Carga el √≠ndice desde disco"""
        self.index = faiss.read_index(self.INDEX_FILE)
        with open(self.DOCS_FILE, "rb") as f:
            self.docs = pickle.load(f)
        self._build_technical_vocabulary()
        print(f"√çndice cargado con {len(self.docs)} documentos")

    def _build_technical_vocabulary(self):
        """Extrae t√©rminos t√©cnicos desde el JSON para mejorar la detecci√≥n de preguntas t√©cnicas."""
        if not self.docs:
            return

        words = []
        for doc in self.docs:
            content = re.sub(r'^[^:]+:', '', doc).lower()
            words.extend(re.findall(r'\b[a-z√°√©√≠√≥√∫√º√±]{4,}\b', content))

        # Extraer t√©rminos desde el JSON procesado
        json_terms = set()
        with open(self.json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            def extract_keys(obj, prefix=""):
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        json_terms.add(key.lower())
                        extract_keys(value, f"{prefix}{key}_")
                elif isinstance(obj, list):
                    for item in obj:
                        extract_keys(item, prefix)
            extract_keys(data)

        # Agregar t√©rminos extra√≠dos al vocabulario t√©cnico
        word_counts = Counter(words)
        stopwords = {"verificar", "sistema", "datos", "valor"}
        self.technical_terms = {
            word for word, count in word_counts.items()
            if count >= 2 and word not in stopwords
        }
        self.technical_terms.update(json_terms)  # A√±adir t√©rminos del JSON

        print(f"üìå T√©rminos t√©cnicos extra√≠dos: {len(self.technical_terms)}")



    def load_json_data(self):
        """Carga y procesa los datos del JSON especificado en el constructor"""
        try:
            with open(self.json_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            fragmentos = self.procesar_json(data)
            self.add_documents(fragmentos)
            print(f"‚úÖ Documentos indexados: {len(self.docs)}")
            return True
            
        except Exception as e:
            print(f"‚ùå Error al cargar JSON: {str(e)}")
            return False

    def procesar_json(self, data):
        """Procesa el JSON para extraer fragmentos t√©cnicos"""
        fragmentos = []
        
        def extract_values(obj, path=""):
            if isinstance(obj, dict):
                for k, v in obj.items():
                    new_path = f"{path}.{k}" if path else k
                    extract_values(v, new_path)
            elif isinstance(obj, list):
                for item in obj:
                    extract_values(item, path)
            elif isinstance(obj, (int, float, str)):
                if isinstance(obj, (int, float)) or (str(obj).strip() and len(str(obj).strip()) > 1):
                    fragmentos.append(f"{path}: {obj}")  # Asegurar que todo se indexe

        extract_values(data)
        return fragmentos



    def add_documents(self, texts):
        """A√±ade documentos al √≠ndice"""
        if not texts:
            return
            
        embeddings = self.model.encode(texts, convert_to_numpy=True)
        self.index.add(embeddings.astype('float32'))
        self.docs.extend(texts)
        self._build_technical_vocabulary()
        self.save_index()

    def save_index(self):
        """Guarda el √≠ndice en disco"""
        faiss.write_index(self.index, self.INDEX_FILE)
        with open(self.DOCS_FILE, "wb") as f:
            pickle.dump(self.docs, f)

    def is_technical_question(self, question):
        """Determina si la pregunta es t√©cnica en funci√≥n de los t√©rminos extra√≠dos del JSON."""
        question = question.lower()
        question_terms = set(re.findall(r'\b[a-z√°√©√≠√≥√∫√º√±]{4,}\b', question))

        # Verificar si la pregunta contiene t√©rminos t√©cnicos extra√≠dos
        if question_terms & self.technical_terms:
            return True

        # Extraer patrones de preguntas t√©cnicas desde las claves del JSON
        common_patterns = {key.replace("_", " ") for key in self.technical_terms if len(key) > 3}

        if any(pattern in question for pattern in common_patterns):
            return True

        return False

    def preprocess_query(self, query):
        """Normaliza y expande la consulta para mejorar la b√∫squeda."""
        query = query.lower().strip()

        # Expansi√≥n de sin√≥nimos
        synonyms = {
            "potencia": ["kw", "kilovatios", "capacidad"],
            "corriente": ["amperaje", "amperios"],
            "tensi√≥n": ["voltaje", "v"],
            "resistencia": ["ohmios", "Œ©"],
            "velocidad": ["rpm"]
        }

        expanded_query = []
        for word in query.split():
            expanded_query.append(word)
            if word in synonyms:
                expanded_query.extend(synonyms[word])

        # Correcci√≥n de errores ortogr√°ficos simples
        typo_corrections = {
            "potenzia": "potencia",
            "voltage": "tensi√≥n",
            "amperage": "corriente"
        }
        expanded_query = [typo_corrections.get(word, word) for word in expanded_query]

        return " ".join(expanded_query)

    # def preprocess_query(self, query):
    #     """Normaliza y expande la consulta para mejorar la b√∫squeda."""
    #     query = query.lower().strip()

    #     # Expansi√≥n de sin√≥nimos
    #     synonyms = {
    #         "potencia": ["kw", "kilovatios"],
    #         "corriente": ["amperaje", "amperios"],
    #         "tensi√≥n": ["voltaje", "v"],
    #         "resistencia": ["ohmios", "Œ©"],
    #         "velocidad": ["rpm"]
    #     }

    #     expanded_query = []
    #     for word in query.split():
    #         expanded_query.append(word)
    #         if word in synonyms:
    #             expanded_query.extend(synonyms[word])

    #     return " ".join(expanded_query)

    def search(self, question, top_k=5):
        """
        Busca en los embeddings solo si es pregunta t√©cnica.
        Devuelve lista vac√≠a para preguntas generales o consultas sin relaci√≥n con los datos.
        """
        if not self.is_technical_question(question):
            return []

        question = self.preprocess_query(question)

        # üö® Filtro sem√°ntico antes de buscar
        if not any(term in question for term in self.technical_terms):
            return []

        query_embedding = self.model.encode([question])
        distances, indices = self.index.search(query_embedding.astype('float32'), top_k)

        results = [(self.docs[idx], distances[0][i]) for i, idx in enumerate(indices[0]) if idx < len(self.docs)]

        # Aplicar filtro de relevancia con la consulta como par√°metro
        results = self._apply_relevance_boost(results, question)

        # üö® Excluir `palabras_clave` y `serie` en preguntas generales
        if not self.is_technical_question(question):
            results = [
                doc for doc in results
                if "palabras_clave" not in doc.lower() and "serie" not in doc.lower() and "n.i" not in doc.lower()
            ]

        return results




    # def search(self, question, top_k=5):
    #     """
    #     Busca en los embeddings solo si es pregunta t√©cnica.
    #     Devuelve lista vac√≠a para preguntas generales o consultas sin relaci√≥n con los datos.
    #     """
    #     if not self.is_technical_question(question):
    #         return []

    #     question = self.preprocess_query(question)

    #     # üö® Filtro sem√°ntico antes de buscar
    #     if not any(term in question for term in self.technical_terms):
    #         return []

    #     query_embedding = self.model.encode([question])
    #     distances, indices = self.index.search(query_embedding.astype('float32'), top_k)

    #     results = [(self.docs[idx], distances[0][i]) for i, idx in enumerate(indices[0]) if idx < len(self.docs)]

    #     # Aplicar filtro de relevancia con la consulta como par√°metro
    #     results = self._apply_relevance_boost(results, question)

    #     # üö® Excluir `palabras_clave` en preguntas generales
    #     if not self.is_technical_question(question):
    #         results = [doc for doc in results if "palabras_clave" not in doc.lower()]

    #     return results

    def _get_document_weight(self, doc_tuple):
        """
        Asigna un peso a cada documento basado en su contenido o metadatos.
        Puede ajustarse seg√∫n reglas espec√≠ficas de negocio.
        """
        doc = doc_tuple[0]  # Extrae el documento de la tupla

        # Caso base: peso por defecto
        weight = 1.0

        # Si el documento tiene ciertas palabras clave, aumentar el peso
        keywords = ["alta tension", "prueba el√©ctrica", "revisi√≥n", "mantenimiento"]
        if any(keyword in doc.lower() for keyword in keywords):
            weight = 0.8  # Mayor prioridad a pruebas el√©ctricas y mantenimiento

        # Si el documento es una recomendaci√≥n, reducir su peso (ejemplo)
        if "recomendaciones_generales" in doc.lower():
            weight = 1.2  # Se considera menos prioritario que los datos t√©cnicos

        return weight


    # def _apply_relevance_boost(self, results, query):
    #     """Prioriza valores t√©cnicos clave y evita divisi√≥n por cero en palabras clave irrelevantes."""
    #     boosted_results = []

    #     FIELD_WEIGHTS = {
    #         'potencia_kw': 10.0,  # Aumentar prioridad de la potencia
    #         'tensi√≥n': 3.0, 'corriente': 3.0,
    #         'resistencia': 3.0, 'prueba': 2.0, 'falla': 1.8,
    #         'ajuste': 1.8, 'velocidad': 1.5, 'rpm': 1.5,
    #         'palabras_clave': 0.1,  # Casi sin peso para evitar coincidencias d√©biles
    #         'serie': 0.1, 'trabajos_realizados': 0.3
    #     }
    def _apply_relevance_boost(self, results, query):
        """Prioriza valores t√©cnicos clave y evita responder preguntas generales."""
        boosted_results = []

        FIELD_WEIGHTS = {
            'potencia_kw': 10.0,  # Aumentar prioridad de la potencia
            'tensi√≥n': 3.0, 'corriente': 3.0,
            'resistencia': 3.0, 'prueba': 2.0, 'falla': 1.8,
            'ajuste': 1.8, 'velocidad': 1.5, 'rpm': 1.5,
            'trabajos_realizados': 0.3
        }

        # Lista de t√©rminos t√©cnicos v√°lidos en el √≠ndice
        TECHNICAL_TERMS = [
            "potencia", "kw", "tensi√≥n", "corriente", "resistencia",
            "prueba", "falla", "ajuste", "velocidad", "rpm",
            "aislamiento", "motor", "ventilador", "tierra", "impulso"
        ]

        # üö® Si la consulta no contiene t√©rminos t√©cnicos, detener la b√∫squeda
        if not any(term in query.lower() for term in TECHNICAL_TERMS):
            return []

        for doc, score in results:
            weight = 1.0  

            # Aplicar pesos seg√∫n campos t√©cnicos encontrados
            for field, field_weight in FIELD_WEIGHTS.items():
                if field in doc.lower():
                    weight *= field_weight
                    break

            boosted_results.append((doc, score / weight))

        boosted_results.sort(key=lambda x: x[1])

        # üö® Filtro especial para la pregunta de potencia
        if "potencia" in query and "kw" in query:
            filtered_results = [doc for doc, _ in boosted_results if "potencia_kw" in doc.lower()]
            if filtered_results:
                return filtered_results  

        # Filtrar respuestas d√©biles (evitar palabras clave sin contexto)
        filtered_results = [doc for doc, _ in boosted_results if "palabras_clave" not in doc.lower()]

        return filtered_results if filtered_results else []




        # boosted_results = []

        # FIELD_WEIGHTS = {
        #     'potencia_kw': 5.0, 'tensi√≥n': 4.0, 'corriente': 3.5,
        #     'resistencia': 4.0, 'prueba': 2.5, 'falla': 2.0,
        #     'ajuste': 1.8, 'velocidad': 1.6, 'rpm': 1.6,
        #     'palabras_clave': 0.1,  # üö® Se evita que sea 0 para prevenir divisi√≥n por cero
        #     'serie': 0.1  # üö® Se evita que "serie" tenga peso relevante
        # }

        # for doc, score in results:
        #     weight = 1.0  

        #     # Aplicar pesos seg√∫n campos t√©cnicos encontrados
        #     for field, field_weight in FIELD_WEIGHTS.items():
        #         if field in doc.lower():
        #             weight *= field_weight
        #             break

        #     # üö® Evitar divisi√≥n por cero asegurando que el peso m√≠nimo sea 0.1
        #     boosted_results.append((doc, score / max(weight, 0.1)))

        # boosted_results.sort(key=lambda x: x[1])

        # return [doc for doc, _ in boosted_results]
    
        # """
        # Ajusta la relevancia de los resultados en funci√≥n de pesos adicionales.
        # Evita divisiones por cero y garantiza que los resultados se ordenen correctamente.
        # """
        # boosted_results = []
        
        # for doc_tuple in results:
        #     weight = self._get_document_weight(doc_tuple)  # Se pasa la tupla completa
            
        #     # üö® Evita divisi√≥n por cero asegurando un peso m√≠nimo
        #     weight = max(weight, 1e-6)
            
        #     # Aplica la ponderaci√≥n ajustada
        #     adjusted_score = doc_tuple[1] / weight
        #     boosted_results.append((doc_tuple[0], adjusted_score))
        
        # # Ordenar por puntuaci√≥n ajustada (mayor relevancia primero)
        # return sorted(boosted_results, key=lambda x: x[1], reverse=True)



    
        # boosted_results = []

        # FIELD_WEIGHTS = {
        #     'potencia_kw': 10.0,  # Aumentar prioridad de la potencia
        #     'tensi√≥n': 3.0, 'corriente': 3.0,
        #     'resistencia': 3.0, 'prueba': 2.0, 'falla': 1.8,
        #     'ajuste': 1.8, 'velocidad': 1.5, 'rpm': 1.5,
        #     'palabras_clave': 0.1  # Casi sin peso para evitar coincidencias d√©biles
        # }

        # for doc, score in results:
        #     weight = 1.0  

        #     # Aplicar pesos seg√∫n campos t√©cnicos encontrados
        #     for field, field_weight in FIELD_WEIGHTS.items():
        #         if field in doc.lower():
        #             weight *= field_weight
        #             break

        #     boosted_results.append((doc, score / weight))

        # boosted_results.sort(key=lambda x: x[1])

        # # üö® Filtro especial para la pregunta de potencia
        # if "potencia" in query and "kw" in query:
        #     filtered_results = [doc for doc, _ in boosted_results if "potencia_kw" in doc.lower()]
        #     if filtered_results:
        #         return filtered_results  

        # # Filtrar respuestas d√©biles (evitar palabras clave sin contexto)
        # filtered_results = [doc for doc, _ in boosted_results if "palabras_clave" not in doc.lower()]
        # return filtered_results if filtered_results else [doc for doc, _ in boosted_results]

    # def display_results(self, question, results):
    #     """Muestra los resultados de b√∫squeda con m√°s contexto."""
    #     if not results:
    #         print(f"\nüîç No se encontraron resultados t√©cnicos para: '{question}'")
    #         print("‚ÑπÔ∏è Esta parece ser una pregunta general o no relacionada con los datos t√©cnicos")
    #         return

    #     print(f"\nüîç Resultados t√©cnicos para: '{question}'\n")
    #     for i, result in enumerate(results, 1):
    #         doc = result[0]  # Extrae el documento de la tupla

    #         if ":" in doc:
    #             field, value = doc.split(":", 1)  # Divide solo en la primera aparici√≥n de ":"
    #             print(f"{i}. {field.strip()} ‚Üí {value.strip()}")
    #         else:
    #             print(f"{i}. {doc}")  # Si no hay ":", imprime el documento completo


    def display_results(self, question, results):
        """Muestra los resultados de b√∫squeda"""
        if not results:
            print(f"\nüîç No se encontraron resultados t√©cnicos para: '{question}'")
            print("‚ÑπÔ∏è Esta parece ser una pregunta general o no relacionada con los datos t√©cnicos")
            return
        
        print(f"\nüîç Resultados t√©cnicos para: '{question}'\n")
        for i, doc in enumerate(results, 1):
            print(f"{i}. {doc}")


if __name__ == "__main__":
    # Opci√≥n 1 (con JSON por defecto "data.json"):
    store = EmbeddingStore()  
    # store.load_json_data()


    # preguntas_tecnicas = [
    # "¬øCu√°l es la potencia en kw del motor?",
    # "¬øCu√°les fueron los trabajos realizados en la reparaci√≥n?",
    # "¬øQu√© pruebas el√©ctricas se realizaron?",
    # "¬øCu√°l fue la resistencia de aislamiento a tierra en GŒ©?",
    # "¬øCu√°l es la velocidad en RPM del motor en vac√≠o?",
    # "¬øQu√© recomendaciones generales se dieron para el mantenimiento del motor?",
    # "¬øQu√© pruebas de alta tensi√≥n se realizaron?",
    # "¬øCu√°l es la tensi√≥n de prueba en la prueba de impulso?",
    # "¬øQu√© tipo de ajuste se hizo en el ventilador?",
    # "¬øQu√© fallas se encontraron en el equipo?"
    # ]

    # preguntas_generales = [
    #     "¬øQu√© hora es en Par√≠s?",
    #     "¬øQui√©n gan√≥ el √∫ltimo mundial de f√∫tbol?",
    #     "¬øC√≥mo est√° el clima hoy?",
    #     "¬øCu√°l es la capital de Francia?",
    #     "¬øQui√©n es el presidente de Estados Unidos?",
    #     "¬øC√≥mo hacer una pizza casera?",
    #     "¬øCu√°nto es 2+2?",
    #     "¬øQu√© significa la palabra 'resiliencia'?",
    #     "¬øD√≥nde queda el Monte Everest?",
    #     "¬øCu√°l es la mejor serie de Netflix?",
    #     "como esta el clima en Cali, Colombia?"
    # ]

    # # Probar preguntas t√©cnicas
    # print("\nüîç **Pruebas con preguntas t√©cnicas**")
    # for pregunta in preguntas_tecnicas:
    #     resultados = store.search(pregunta)
    #     store.display_results(pregunta, resultados)

    # # Probar preguntas generales
    # print("\nüîç **Pruebas con preguntas generales**")
    # for pregunta in preguntas_generales:
    #     resultados = store.search(pregunta)
    #     store.display_results(pregunta, resultados)